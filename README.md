# Deep Reinforcement Learning Coursework
![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/pytorch-2.0-orange)
![Reinforcement Learning](https://img.shields.io/badge/field-Reinforcement%20Learning-purple)
![Gym](https://img.shields.io/badge/env-OpenAI%20Gym-yellow)
![RLlib](https://img.shields.io/badge/framework-RLlib-red)
![Weights & Biases](https://img.shields.io/badge/tracking-W%26B-black)
![License](https://img.shields.io/badge/license-MIT-green)


# Deep Reinforcement Learning Coursework

This repository contains my coursework for the **Deep Reinforcement Learning** module.
The project explores classical and deep RL algorithms across environments of increasing complexity,
from tabular GridWorld to high-dimensional visual Atari environments.

The implementation covers **Q-learning, DQN (with improvements), PPO, and SAC**, with
systematic evaluation and visualization of learning behavior.

---

## ğŸ” Project Overview

The coursework is organized into three main sections:

### 1ï¸âƒ£ Basic â€” Tabular Reinforcement Learning

- Implemented a **5Ã—5 GridWorld** environment with obstacles
- Defined deterministic state transition and reward functions
- Trained an agent using **Q-learning**
- Tuned learning rate (Î±), discount factor (Î³), and exploration rate (Îµ)
- Evaluated learning using:
  - Cumulative reward per episode
  - Episode length trends
  - Learned policy heatmaps

ğŸ“Š Results and visualizations are stored in the `outputs/` directory.

---

### 2ï¸âƒ£ Advanced â€” Deep Reinforcement Learning

This section extends learning to environments that require function approximation.

- **Deep Q-Network (DQN)**
  - Implemented neural-network-based Q-learning
  - Used experience replay for training stability

- **RLlib on Atari (Pong)**
  - Trained an agent on a high-dimensional pixel-based environment
  - Applied policy-gradient-based RL using RLlib
  - Tracked performance metrics such as episode return, length, loss, and KL divergence

ğŸ“ˆ Training logs and metrics for Atari experiments are available on Weights & Biases:

ğŸ‘‰ https://wandb.ai/anndischeh-univ-/Deep%20Reinforcement%20Learning

---

### 3ï¸âƒ£ Extras â€” Soft Actor-Critic (SAC)

- Implemented **Soft Actor-Critic (SAC)** on CartPole-v1
- Used:
  - Gaussian policy network
  - Twin Q-networks with target networks
  - Experience replay buffer
  - Automatic entropy tuning
- Mapped continuous policy outputs to discrete actions
- Analyzed reward curves and loss evolution

âœ… Results and plots are saved in `outputs/`.

---

## ğŸ“ Project Structure
```
C:.
â”œâ”€â”€ Advanced.py                         # Implementation of the advanced reinforcement learning algorithms and experiments.
â”œâ”€â”€ Advanced_rllib.py                   # RLlib-based implementation and training on Atari environment.
â”œâ”€â”€ Basic.py                           # Basic GridWorld environment and Q-learning implementation.
â”œâ”€â”€ Extras.py                          # Extra experiments including Soft Actor-Critic (SAC) on CartPole.
â”œâ”€â”€ requirements.txt                   # List of Python dependencies for the project.
â””â”€â”€ outputs/                          # Folder containing all results and logs generated during training and evaluation.
    â”œâ”€â”€ Advanced_log.txt               # Training logs for Advanced experiments.
    â”œâ”€â”€ Advanced_Training Progress-Loss.png    # Training loss curve for Advanced experiments.
    â”œâ”€â”€ Advanced_Training Progress-Reward.png  # Training reward curve for Advanced experiments.
    â”œâ”€â”€ Basic_Best-Performing-Parameter.png    # Visualization of best parameters found in Basic experiments.
    â”œâ”€â”€ Basic_Learned-Policy-2.png     # Learned policy visualization for Basic experiments.
    â”œâ”€â”€ Basic_Learned-policy.png       # Another learned policy visualization for Basic experiments.
    â”œâ”€â”€ Basic_log.txt                  # Training logs for Basic experiments.
    â”œâ”€â”€ Basic_Q-Learning-Episode.png  # Q-learning episode performance plot.
    â”œâ”€â”€ episode_stats.png              # General episode statistics visualization.
    â”œâ”€â”€ Extras_log.txt                 # Training logs for Extras experiments.
    â”œâ”€â”€ Extra_Learned-Policy.png       # Learned policy visualization for Extras experiments.
    â”œâ”€â”€ Figure_1.png                   # Additional result figure.
    â”œâ”€â”€ Figure_2.png                   # Additional result figure.
    â”œâ”€â”€ Figure_3.png                   # Additional result figure.
    â”œâ”€â”€ Figure_4.png                   # Additional result figure.
    â”œâ”€â”€ training_results.png           # Summary plot of training results.
    â””â”€â”€ Videos/                       # Folder containing recorded training episodes.
        â”œâ”€â”€ rl-video-episode-0.mp4    # Training episode video 0.
        â”œâ”€â”€ rl-video-episode-1.mp4    # Training episode video 1.
        â””â”€â”€ rl-video-episode-2.mp4    # Training episode video 2.

```

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```
### 2ï¸âƒ£ Run Experiments
#### ğŸ”¹ Basic (Q-learning - GridWorld):

```bash
python basic.py
```
#### ğŸ”¹ Advanced (Deep Q-Network (DQN)):
```bash
python Advanced.py
```
#### ğŸ”¹Advanced (RLlib Atari Training):
This script supports configurable hardware resources and distributed training parameters.
```bash
python Advanced_rllib.py \
  --num-cpus=2 \
  --num-env-runners=1 \
  --num-learners=1 \
  --num-gpus-per-learner=1 \
  --framework=torch
```
Notes:
- Adjust CPU/GPU values based on your available hardware
- Uses RLlib for scalable reinforcement learning
- Results and training logs are tracked via Weights & Biases
  
### ğŸ”¹ Extras - Soft Actor-Critic on CarPole (SAC):
```bash
python Extras.py
```
------------
## ğŸ“Œ Key Takeaways

- Implemented and compared tabular, value-based, and policy-gradient RL algorithms
- Gained hands-on experience with:
  - Explorationâ€“exploitation trade-offs
  - Stability improvements in deep RL
  - High-dimensional visual environments
- Ensured experiment reproducibility and visualization using Weights & Biases

## ğŸ“š References

- Sutton & Barto â€” Reinforcement Learning: An Introduction
- OpenAI Gym
- RLlib Documentation


*Note: The command uses `python`, not `!python`, unless you are executing within a Jupyter notebook.*

